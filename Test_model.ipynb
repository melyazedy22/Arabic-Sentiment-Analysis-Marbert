{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Arabic Sentiment Analysis: Model Testing\n",
                "This notebook is specifically designed to test the **MARBERT** model trained for Arabic sentiment classification.\n",
                "\n",
                "### Project Info:\n",
                "- **Model:** UBC-NLP/MARBERT\n",
                "- **Classes:** 0 (Negative), 1 (Positive), 2 (Neutral)\n",
                "- **Utilities:** Uses `./utils/preprocessing.py` for consistent text cleaning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2713 Environment initialized. If you just installed 'accelerate', please restart your kernel.\n"
                    ]
                }
            ],
            "source": [
                "# 0. Setup Environment\n",
                "# Run this cell if you haven't installed dependencies or if you get 'BertForSequenceClassification' errors\n",
                "!pip install -q transformers[torch] accelerate datasets evaluate scikit-learn\n",
                "print(\"\u2713 Environment initialized. If you just installed 'accelerate', please restart your kernel.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2713 Dependencies imported\n"
                    ]
                }
            ],
            "source": [
                "# 1. Import Dependencies\n",
                "import torch\n",
                "import json\n",
                "import os\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertForSequenceClassification\n",
                "from utils.preprocessing import clean_arabic_text\n",
                "\n",
                "print(\"\u2713 Dependencies imported\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading model from './final_model' to cpu...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading weights: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201/201 [00:00<00:00, 427.03it/s, Materializing param=classifier.weight]                                      \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2713 Model and Tokenizer loaded successfully\n",
                        "  Class labels: {0: 'negative', 1: 'positive', 2: 'neutral'}\n"
                    ]
                }
            ],
            "source": [
                "# 2. Load Model & label Map\n",
                "MODEL_PATH = './final_model'\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "print(f\"Loading model from '{MODEL_PATH}' to {device}...\")\n",
                "\n",
                "try:\n",
                "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
                "    try:\n",
                "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
                "    except Exception:\n",
                "        model = BertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
                "    model.to(device)\n",
                "    model.eval()\n",
                "    \n",
                "    # Load label mapping\n",
                "    label_map_path = os.path.join(MODEL_PATH, 'label_map.json')\n",
                "    if os.path.exists(label_map_path):\n",
                "        with open(label_map_path, 'r', encoding='utf-8') as f:\n",
                "            label_dict = json.load(f)\n",
                "            id2label = {int(k): v for k, v in label_dict['id2label'].items()}\n",
                "    else:\n",
                "        id2label = model.config.id2label\n",
                "        \n",
                "    print(\"\u2713 Model and Tokenizer loaded successfully\")\n",
                "    print(f\"  Class labels: {id2label}\")\n",
                "except Exception as e:\n",
                "    print(f\"\u274c Error: {e}\")\n",
                "    print(\"\\n--- Troubleshooting Tips ---\")\n",
                "    print(\"1. Ensure 'final_model' folder exists and contains 'model.safetensors'.\")\n",
                "    print(\"2. If you see 'BertForSequenceClassification' error, run Cell 0 and Restart Kernel.\")\n",
                "    model = None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u2713 Prediction function ready\n"
                    ]
                }
            ],
            "source": [
                "# 3. Unified Prediction Logic\n",
                "def get_sentiment(text):\n",
                "    if model is None:\n",
                "        return \"Model not loaded\", 0.0\n",
                "        \n",
                "    # 1. Clean\n",
                "    cleaned_text = clean_arabic_text(text)\n",
                "    \n",
                "    # 2. Tokenize\n",
                "    inputs = tokenizer(cleaned_text, return_tensors=\"pt\", \n",
                "                       truncation=True, padding=True, max_length=512).to(device)\n",
                "    \n",
                "    # 3. Predict\n",
                "    with torch.no_grad():\n",
                "        outputs = model(**inputs)\n",
                "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
                "        \n",
                "    # 4. Result\n",
                "    idx = torch.argmax(probs, dim=-1).item()\n",
                "    return id2label[idx], probs[0][idx].item()\n",
                "\n",
                "print(\"\u2713 Prediction function ready\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Text                                               | Prediction | Confidence\n",
                        "---------------------------------------------------------------------------\n",
                        "\u062e\u062f\u0645\u0629 \u0631\u0627\u0626\u0639\u0629 \u0648\u0633\u0631\u064a\u0639\u0629 \u062c\u062f\u0627\u064b \u0634\u0643\u0631\u0627\u064b \u0644\u0643\u0645...                | POSITIVE   | 91.05%    \n",
                        "\u0644\u0644\u0623\u0633\u0641 \u062a\u062c\u0631\u0628\u0629 \u0633\u064a\u0626\u0629 \u0644\u0644\u063a\u0627\u064a\u0629 \u0648\u0644\u0646 \u0623\u0643\u0631\u0631\u0647\u0627...              | NEUTRAL    | 54.15%    \n",
                        "\u0627\u0644\u0645\u0646\u062a\u062c \u0648\u0635\u0644 \u0641\u064a \u0645\u0648\u0639\u062f\u0647 \u0648\u0627\u0644\u062a\u063a\u0644\u064a\u0641 \u062c\u064a\u062f...                | POSITIVE   | 83.39%    \n",
                        "\u0645\u0633\u062a\u0648\u0649 \u0639\u0627\u062f\u064a \u062c\u062f\u0627 \u0643\u0628\u0627\u0642\u064a \u0627\u0644\u0645\u0637\u0627\u0639\u0645...                    | NEUTRAL    | 77.84%    \n"
                    ]
                }
            ],
            "source": [
                "# 4. Run Benchmarks\n",
                "benchmarks = [\n",
                "    (\"\u062e\u062f\u0645\u0629 \u0631\u0627\u0626\u0639\u0629 \u0648\u0633\u0631\u064a\u0639\u0629 \u062c\u062f\u0627\u064b \u0634\u0643\u0631\u0627\u064b \u0644\u0643\u0645\", \"Positive\"),\n",
                "    (\"\u0644\u0644\u0623\u0633\u0641 \u062a\u062c\u0631\u0628\u0629 \u0633\u064a\u0626\u0629 \u0644\u0644\u063a\u0627\u064a\u0629 \u0648\u0644\u0646 \u0623\u0643\u0631\u0631\u0647\u0627\", \"Negative\"),\n",
                "    (\"\u0627\u0644\u0645\u0646\u062a\u062c \u0648\u0635\u0644 \u0641\u064a \u0645\u0648\u0639\u062f\u0647 \u0648\u0627\u0644\u062a\u063a\u0644\u064a\u0641 \u062c\u064a\u062f\", \"Neutral/Positive\"),\n",
                "    (\"\u0645\u0633\u062a\u0648\u0649 \u0639\u0627\u062f\u064a \u062c\u062f\u0627 \u0643\u0628\u0627\u0642\u064a \u0627\u0644\u0645\u0637\u0627\u0639\u0645\", \"Neutral\")\n",
                "]\n",
                "\n",
                "if model:\n",
                "    print(\"{:<50} | {:<10} | {:<10}\".format(\"Text\", \"Prediction\", \"Confidence\"))\n",
                "    print(\"-\"*75)\n",
                "    for text, expected in benchmarks:\n",
                "        label, conf = get_sentiment(text)\n",
                "        print(\"{:<50} | {:<10} | {:<10.2%}\".format(text[:47] + \"...\", label.upper(), conf))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Input: \u0648\u062d\u0634\u0647 \u0627\u0648\u064a\n",
                        "Prediction: NEGATIVE (60.95% confidence)\n"
                    ]
                }
            ],
            "source": [
                "# 5. Interactive Test\n",
                "if model:\n",
                "    user_input = input(\"Enter Arabic text to analyze: \")\n",
                "    if user_input.strip():\n",
                "        label, conf = get_sentiment(user_input)\n",
                "        print(f\"\\nInput: {user_input}\")\n",
                "        print(f\"Prediction: {label.upper()} ({conf:.2%} confidence)\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv (3.10.11)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}